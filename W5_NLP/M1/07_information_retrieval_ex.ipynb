{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669a3790",
   "metadata": {},
   "source": [
    "# Information Retrieval\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lab provides hands-on practice building a complete **Search Engine** from scratch using **TF-IDF (Term Frequency-Inverse Document Frequency)**, one of the most common techniques in Information Retrieval. You'll work with real datasets, implement TF-IDF vectorization, measure document similarity using cosine similarity, and build a functional search engine that can retrieve and rank documents based on user queries. This lab demonstrates the practical application of IR concepts in building production-ready search systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54002715",
   "metadata": {},
   "source": [
    "> A 2015 survey showed that 83% of text-based recommender systems in digital libraries used TF-IDF.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Setup and Imports** - Installing dependencies and importing libraries\n",
    "2. **Dataset Loading** - Loading the 20 Newsgroups dataset from scikit-learn\n",
    "3. **Text Preprocessing** - Preparing documents for vectorization\n",
    "4. **TF-IDF Vectorization** - Converting documents and queries into numerical vectors\n",
    "5. **Building the Search Engine**:\n",
    "   - **Retrieval**: Finding the most similar documents to a query using cosine similarity\n",
    "   - **Ranking**: Ordering documents by relevance score\n",
    "   - **Classification**: Classifying queries into one of the 20 categories\n",
    "6. **Testing the Search Engine** - Querying and evaluating results\n",
    "7. **Understanding Results** - Interpreting search results and similarity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a535e",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Recognize the term-document matrix produced by the TF-IDF algorithm\n",
    "- Understand how similarity is measured between text vectors (cosine similarity)\n",
    "- **Work with real datasets**.\n",
    "- **Implement a TF-IDF-based search engine** using:\n",
    "  - Scikit-learn's `TfidfVectorizer`\n",
    "  - Cosine similarity for document ranking\n",
    "  - Sparse matrices for efficient storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff080ff",
   "metadata": {},
   "source": [
    "## Glossary of Terms\n",
    "\n",
    "**Information Retrieval (IR)**: The task of finding information (usually documents) that satisfies an information need from within large collections.\n",
    "\n",
    "**Corpus**: A collection of documents. In IR, this is the entire set of documents we search through.\n",
    "\n",
    "**Query**: A user's information need expressed in natural language (e.g., \"What is machine learning?\").\n",
    "\n",
    "**Document**: A unit of information in the corpus (e.g., a web page, article, or text passage).\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)**: A numerical statistic that reflects how important a word is to a document in a collection. As you learned in the vectorization lesson:\n",
    "- **TF (Term Frequency)**: How often a term appears in a document\n",
    "- **IDF (Inverse Document Frequency)**: How rare or common a term is across the entire corpus\n",
    "- **TF-IDF**: TF × IDF, giving higher weight to terms that are frequent in a document but rare in the corpus\n",
    "\n",
    "**Vector Space Model**: A model where documents and queries are represented as vectors in a high-dimensional space. Similarity is measured using the angle between vectors (cosine similarity).\n",
    "\n",
    "**Cosine Similarity**: A measure of similarity between two vectors. It measures the cosine of the angle between them, ranging from -1 to 1 (or 0 to 1 for non-negative vectors like TF-IDF).\n",
    "\n",
    "**Sparse Matrix**: A matrix where most elements are zero. TF-IDF vectors are typically sparse because most words don't appear in most documents.\n",
    "\n",
    "**Retrieval**: The process of finding and ranking documents in response to a query.\n",
    "\n",
    "**Ranking**: Ordering retrieved documents by their relevance score (highest to lowest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c451be65",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [20 Newsgroups Dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)\n",
    "- [Scikit-learn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- [Scikit-learn cosine_similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73007603",
   "metadata": {},
   "source": [
    "## The Complete Pipeline\n",
    "\n",
    "1. **Dataset Loading**: Load the 20 Newsgroups dataset from scikit-learn\n",
    "2. **Text Preprocessing**: Prepare documents for vectorization (as learned in previous lessons)\n",
    "3. **TF-IDF Vectorization**: Convert documents and queries into numerical vectors\n",
    "4. Model:\n",
    "   1. **Retrieval**: Find the most similar documents to a query using **cosine similarity**\n",
    "   2. **Classification**: Classify a query into one of the 20 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e643e",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "We group imports by category following Python best practices. All libraries used here are part of the standard scikit-learn ecosystem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install joblib==1.5.3 numpy==1.26.4 pandas==2.3.3 scikit-learn==1.8.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f436a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3172c8",
   "metadata": {},
   "source": [
    "## Loading the 20 Newsgroups Dataset\n",
    "\n",
    "We'll use scikit-learn's **20 Newsgroups dataset**, a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups. This is a classic dataset for text classification and information retrieval experiments.\n",
    "\n",
    "**About the Dataset:**\n",
    "- **20 categories** of newsgroups (e.g., comp.graphics, rec.sport.baseball, sci.med)\n",
    "- Each document is a newsgroup post with subject and body text\n",
    "- Documents are organized by topic, which we'll use to create relevance judgments\n",
    "\n",
    "We'll load the 20 Newsgroups dataset using scikit-learn's `fetch_20newsgroups` function. This dataset contains newsgroup posts organized into 20 categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48eb4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6705ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "fetch_20newsgroups(\n",
      "    *,\n",
      "    data_home=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    subset=\u001b[33m'train'\u001b[39m,\n",
      "    categories=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    random_state=\u001b[32m42\u001b[39m,\n",
      "    remove=(),\n",
      "    download_if_missing=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    return_X_y=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    n_retries=\u001b[32m3\u001b[39m,\n",
      "    delay=\u001b[32m1.0\u001b[39m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "\n",
      "Download it if necessary.\n",
      "\n",
      "=================   ==========\n",
      "Classes                     20\n",
      "Samples total            18846\n",
      "Dimensionality               1\n",
      "Features                  text\n",
      "=================   ==========\n",
      "\n",
      "Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data_home : str or path-like, default=None\n",
      "    Specify a download and cache folder for the datasets. If None,\n",
      "    all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "\n",
      "subset : {'train', 'test', 'all'}, default='train'\n",
      "    Select the dataset to load: 'train' for the training set, 'test'\n",
      "    for the test set, 'all' for both, with shuffled ordering.\n",
      "\n",
      "categories : array-like, dtype=str, default=None\n",
      "    If None (default), load all the categories.\n",
      "    If not None, list of category names to load (other categories\n",
      "    ignored).\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Whether or not to shuffle the data: might be important for models that\n",
      "    make the assumption that the samples are independent and identically\n",
      "    distributed (i.i.d.), such as stochastic gradient descent.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=42\n",
      "    Determines random number generation for dataset shuffling. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "remove : tuple, default=()\n",
      "    May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "    these are kinds of text that will be detected and removed from the\n",
      "    newsgroup posts, preventing classifiers from overfitting on\n",
      "    metadata.\n",
      "\n",
      "    'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "    ends of posts that look like signatures, and 'quotes' removes lines\n",
      "    that appear to be quoting another post.\n",
      "\n",
      "    'headers' follows an exact standard; the other filters are not always\n",
      "    correct.\n",
      "\n",
      "download_if_missing : bool, default=True\n",
      "    If False, raise an OSError if the data is not locally available\n",
      "    instead of trying to download the data from the source site.\n",
      "\n",
      "return_X_y : bool, default=False\n",
      "    If True, returns `(data.data, data.target)` instead of a Bunch\n",
      "    object.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "n_retries : int, default=3\n",
      "    Number of retries when HTTP errors are encountered.\n",
      "\n",
      "    .. versionadded:: 1.5\n",
      "\n",
      "delay : float, default=1.0\n",
      "    Number of seconds between retries.\n",
      "\n",
      "    .. versionadded:: 1.5\n",
      "\n",
      "Returns\n",
      "-------\n",
      "bunch : :class:`~sklearn.utils.Bunch`\n",
      "    Dictionary-like object, with the following attributes.\n",
      "\n",
      "    data : list of shape (n_samples,)\n",
      "        The data list to learn.\n",
      "    target: ndarray of shape (n_samples,)\n",
      "        The target labels.\n",
      "    filenames: list of shape (n_samples,)\n",
      "        The path to the location of the data.\n",
      "    DESCR: str\n",
      "        The full description of the dataset.\n",
      "    target_names: list of shape (n_classes,)\n",
      "        The names of target classes.\n",
      "\n",
      "(data, target) : tuple if `return_X_y=True`\n",
      "    A tuple of two ndarrays. The first contains a 2D array of shape\n",
      "    (n_samples, n_classes) with each row representing one sample and each\n",
      "    column representing the features. The second array of shape\n",
      "    (n_samples,) contains the target samples.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import fetch_20newsgroups\n",
      ">>> cats = ['alt.atheism', 'sci.space']\n",
      ">>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      ">>> list(newsgroups_train.target_names)\n",
      "['alt.atheism', 'sci.space']\n",
      ">>> newsgroups_train.filenames.shape\n",
      "(1073,)\n",
      ">>> newsgroups_train.target.shape\n",
      "(1073,)\n",
      ">>> newsgroups_train.target[:10]\n",
      "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\w\\documents\\my_csv_project\\.venv\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "fetch_20newsgroups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bb6422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 Newsgroups dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load the 20 Newsgroups dataset\n",
    "# We'll use the training set as our document collection\n",
    "# remove=('headers', 'footers', 'quotes') removes metadata to focus on content\n",
    "print(\"Loading 20 Newsgroups dataset...\")\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de287d",
   "metadata": {},
   "source": [
    "### Exercise 1: Explore the Dataset\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- The distribution of documents across categories\n",
    "- The content of sample documents\n",
    "- Notice that documents are organized by topic (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd2d2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  \\\n",
       "0  I was wondering if anyone out there could enli...         7   \n",
       "1  A fair number of brave souls who upgraded thei...         4   \n",
       "2  well folks, my mac plus finally gave up the gh...         4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...         1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...        14   \n",
       "\n",
       "           category_name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': newsgroups.data,\n",
    "    'category': newsgroups.target,\n",
    "    'category_name': [newsgroups.target_names[newsgroups.target[i]] for i in range(len(newsgroups.target))]\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e998e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1145aece",
   "metadata": {},
   "source": [
    "### Drop columns and keep `text` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411a5b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      I was wondering if anyone out there could enli...\n",
       "1      A fair number of brave souls who upgraded thei...\n",
       "2      well folks, my mac plus finally gave up the gh...\n",
       "3      \\nDo you have Weitek's address/phone number?  ...\n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...\n",
       "...                                                  ...\n",
       "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
       "11310  I have a (very old) Mac 512k and a Mac Plus, b...\n",
       "11311  I just installed a DX2-66 CPU in a clone mothe...\n",
       "11312  \\nWouldn't this require a hyper-sphere.  In 3-...\n",
       "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...\n",
       "\n",
       "[11314 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f92865",
   "metadata": {},
   "source": [
    "## Building the Search Engine\n",
    "\n",
    "Now we'll build a TF-IDF-based search engine. The process involves:\n",
    "\n",
    "1. **Creating TF-IDF vectors** for all documents\n",
    "2. **Implementing a retrieval function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c31e6",
   "metadata": {},
   "source": [
    "### How TF-IDF enables retrieval\n",
    "\n",
    "- TF-IDF weights words by their importance: rare words that appear frequently in a document get high scores\n",
    "- When a user searches for \"machine learning\", documents with high TF-IDF scores for those terms are likely relevant\n",
    "- The query is also converted to a TF-IDF vector, then compared to all document vectors\n",
    "\n",
    "**Cosine Similarity for Document Matching**\n",
    "\n",
    "To find relevant documents, we need to measure **similarity** between the query vector and document vectors. \n",
    "\n",
    "**Cosine Similarity** measures the angle between two vectors:\n",
    "- It ranges from -1 to 1 (or 0 to 1 for non-negative vectors like TF-IDF)\n",
    "- **1.0** = vectors point in the same direction (very similar)\n",
    "- **0.0** = vectors are perpendicular (no similarity)\n",
    "- **-1.0** = vectors point in opposite directions (very dissimilar)\n",
    "\n",
    "**Why cosine similarity?**\n",
    "- It measures similarity in **direction**, not magnitude\n",
    "- A long document and a short document about the same topic will have similar directions (high cosine similarity)\n",
    "- It's robust to document length differences\n",
    "- Works well with sparse TF-IDF vectors\n",
    "\n",
    "**The retrieval process:**\n",
    "1. Convert query to TF-IDF vector (using the same vocabulary as documents)\n",
    "2. Compute cosine similarity between query vector and all document vectors\n",
    "3. Rank documents by similarity score (highest first)\n",
    "4. Return top-k most similar documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa43bc",
   "metadata": {},
   "source": [
    "### Task 1: Creating TF-IDF vectors for all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e636eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create TF-IDF vectors for all documents\n",
    "# Initialize the vectorizer\n",
    "# We use default settings, but you can customize:\n",
    "# - max_features: limit vocabulary size\n",
    "# - stop_words: remove common words ('english')\n",
    "# - ngram_range: use unigrams and bigrams\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,      # Convert to lowercase\n",
    "    stop_words='english', # Remove English stop words\n",
    "    max_features=5000,   # Limit vocabulary to top 5000 terms\n",
    "    ngram_range=(1, 2)   # Use both unigrams and bigrams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a74b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 504037 stored elements and shape (11314, 5000)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on all documents and transform them\n",
    "# This learns the vocabulary and IDF from the corpus\n",
    "document_vectors = vectorizer.fit_transform(df['text'])\n",
    "document_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "554ee14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vectors shape: (11314, 5000)\n",
      "  - 11314 documents\n",
      "  - 5000 features (terms in vocabulary)\n",
      "\n",
      "This is a sparse matrix. Let's check sparsity:\n",
      "  - Non-zero elements: 504,037\n",
      "  - Total elements: 56,570,000\n",
      "  - Sparsity: 99.11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document vectors shape: {document_vectors.shape}\")\n",
    "print(f\"  - {document_vectors.shape[0]} documents\")\n",
    "print(f\"  - {document_vectors.shape[1]} features (terms in vocabulary)\")\n",
    "print(\"\\nThis is a sparse matrix. Let's check sparsity:\")\n",
    "print(f\"  - Non-zero elements: {document_vectors.nnz:,}\")\n",
    "print(f\"  - Total elements: {document_vectors.shape[0] * document_vectors.shape[1]:,}\")\n",
    "print(f\"  - Sparsity: {(1 - document_vectors.nnz / (document_vectors.shape[0] * document_vectors.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da4cf8",
   "metadata": {},
   "source": [
    "> Notice how the sparse matrix efficiently stores only non-zero values. This is why TF-IDF scales well to large document collections.\n",
    "\n",
    "- Document vectors shape: (~11,000, 5000) - thousands of documents, 5000 features\n",
    "- High sparsity (typically 95-99%) - most values are zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70896f34",
   "metadata": {},
   "source": [
    "Notice how there is a lot of junk in the text, when we print the vocabulary from `200:400`, this may or may not be useful, depending on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc50001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['415' '42' '43' '44' '45' '46' '47' '48' '486' '49' '4e' '4k' '4l' '4t'\n",
      " '4th' '4u' '50' '500' '5000' '51' '52' '53' '54' '55' '56' '57' '58' '59'\n",
      " '5g' '5g9p' '5g9v' '5k' '5s' '5u' '60' '600' '6000' '61' '617' '62' '63'\n",
      " '64' '65' '650' '66' '67' '68' '69' '6e' '6ei' '6ei 6ei' '6g' '6um'\n",
      " '6um 6um' '70' '700' '703' '71' '72' '73' '74' '75' '750' '75u' '75u 75u'\n",
      " '76' '77' '78' '79' '7ex' '7ey' '7ey 7ey' '7ez' '7klj' '7kn' '7th' '7u'\n",
      " '80' '80 bit' '800' '81' '82' '83' '84' '85' '86' '87' '88' '89' '8n'\n",
      " '8v' '90' '900' '91' '91 92' '92' '93' '94' '95' '96' '97' '98' '99' '9d'\n",
      " '9f' '9f8' '9f9' '9l' '9l3' '9p' '9s' '9v' '9v g9v' '__' '___' '____'\n",
      " '_____' '_q' '_the' 'a4' 'a7' 'a86' 'a86 a86' 'a86 lg' 'a86r' 'ab' 'abc'\n",
      " 'abiding' 'ability' 'able' 'abortion' 'abs' 'absolute' 'absolutely'\n",
      " 'abuse' 'ac' 'ac uk' 'academic' 'accelerator' 'accept' 'acceptable'\n",
      " 'accepted' 'access' 'accident' 'accidents' 'accomplished' 'according'\n",
      " 'account' 'accounts' 'accurate' 'achieve' 'acid' 'acquired' 'act'\n",
      " 'acting' 'action' 'actions' 'active' 'activities' 'activity' 'acts'\n",
      " 'actual' 'actually' 'ad' 'adam' 'adams' 'adaptec' 'adapter' 'add' 'added'\n",
      " 'adding' 'addition' 'additional' 'address' 'addressed' 'addresses'\n",
      " 'addressing' 'adequate' 'adl' 'administration' 'administration official'\n",
      " 'administrator' 'admit' 'admitted' 'adobe' 'ads' 'adult' 'adults'\n",
      " 'advance' 'advanced' 'advantage' 'advertising' 'advice' 'aerospace'\n",
      " 'affairs' 'affect' 'affected' 'afford' 'afraid' 'african']\n"
     ]
    }
   ],
   "source": [
    "# Show some vocabulary terms\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab[200:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d87d0f",
   "metadata": {},
   "source": [
    "### Task 2: Implementing a retrieval function\n",
    "\n",
    "- Converts a query to a TF-IDF vector\n",
    "- Computes cosine similarity with all document vectors\n",
    "- Returns the top-k most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dbddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Implement the retrieval function\n",
    "def retrieve_documents(query_text, top_k=10):\n",
    "    # Transform query to TF-IDF vector using the same vectorizer\n",
    "    query_vector = vectorizer.transform([query_text])\n",
    "    \n",
    "    # Compute cosine similarity between query and all documents\n",
    "    # cosine_similarity returns a matrix of shape (1, num_documents)\n",
    "    similarities = cosine_similarity(query_vector, document_vectors).flatten()\n",
    "    \n",
    "    # Get indices of top-k documents (sorted by similarity, descending)\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    # Return a dataframe with the top-k results\n",
    "    df_results = df.iloc[top_indices].copy()\n",
    "    df_results['similarity'] = similarities[top_indices]\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ded750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>\\nWhat about the common joystick found in all ...</td>\n",
       "      <td>0.675917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>\\n\\nRumor has it that a guy at Dell Computer h...</td>\n",
       "      <td>0.650509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8464</th>\n",
       "      <td>\\n Computers are a special case.. and it's a p...</td>\n",
       "      <td>0.517928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  similarity\n",
       "9137  \\nWhat about the common joystick found in all ...    0.675917\n",
       "8258  \\n\\nRumor has it that a guy at Dell Computer h...    0.650509\n",
       "8464  \\n Computers are a special case.. and it's a p...    0.517928"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = retrieve_documents(query_text='computer', top_k=3)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed705f",
   "metadata": {},
   "source": [
    "> **Note:** how the top three results are all related to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6035e97",
   "metadata": {},
   "source": [
    "## **Student Exercise**: build a search engine on the `CVs` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: 40\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "base_path = './CVs' \n",
    "\n",
    "\n",
    "files = glob.glob(os.path.join(base_path, '*', '*.json'), recursive=True)\n",
    "\n",
    "print(f\"Files found: {len(files)}\")\n",
    "\n",
    "all_cvs = []\n",
    "\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "      \n",
    "        full_text = \" \".join([\n",
    "            data.get('Heading', ''),\n",
    "            \" \".join(data.get('Skills', [])),\n",
    "            \" \".join(data.get('Projects', [])),\n",
    "            \" \".join(data.get('Experience', [])),\n",
    "            \" \".join(data.get('Education', []))\n",
    "        ])\n",
    "        \n",
    "        all_cvs.append({\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'topic': os.path.basename(os.path.dirname(file_path)), \n",
    "            'full_text': full_text\n",
    "        })\n",
    "\n",
    "\n",
    "df_cvs = pd.DataFrame(all_cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d706a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>topic</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_en.json</td>\n",
       "      <td>Topic_1</td>\n",
       "      <td>Ahmed Al-Otaibi, AI Engineer * **Programming L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05_en.json</td>\n",
       "      <td>Topic_1</td>\n",
       "      <td>Layla Al-Harbi, AI Engineer * **Automation &amp; P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07.json</td>\n",
       "      <td>Topic_1</td>\n",
       "      <td>Fatima Al-Zahrani, AI Engineer * **Programming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.json</td>\n",
       "      <td>Topic_1</td>\n",
       "      <td>Ali Bin Nasser, AI Engineer * **Research Areas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.json</td>\n",
       "      <td>Topic_1</td>\n",
       "      <td>Nasser Al-Khaldi, AI Engineer * **Programming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename    topic                                          full_text\n",
       "0  01_en.json  Topic_1  Ahmed Al-Otaibi, AI Engineer * **Programming L...\n",
       "1  05_en.json  Topic_1  Layla Al-Harbi, AI Engineer * **Automation & P...\n",
       "2     07.json  Topic_1  Fatima Al-Zahrani, AI Engineer * **Programming...\n",
       "3     10.json  Topic_1  Ali Bin Nasser, AI Engineer * **Research Areas...\n",
       "4     11.json  Topic_1  Nasser Al-Khaldi, AI Engineer * **Programming ..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ae1ef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmed Al-Otaibi, AI Engineer * **Programming L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Layla Al-Harbi, AI Engineer * **Automation &amp; P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fatima Al-Zahrani, AI Engineer * **Programming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ali Bin Nasser, AI Engineer * **Research Areas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nasser Al-Khaldi, AI Engineer * **Programming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sultan Al-Fahim, AI Engineer * **CI/CD &amp; Autom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dana Al-Jaber, AI Engineer * **Generative Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abdullah Al-Ghamdi, AI Engineer * **Research A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yasmin Al-Jassim, AI Engineer * **Programming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ibrahim Al-Saeed, AI Engineer * **Programming:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hamad Al-Ghanim, Data Scientist * **Python:** ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Faisal Al-Qahtani, AI Engineer * **Infrastruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nouf Al-Hamad, AI Engineer * **Model Deploymen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Omar Bin Talal, AI Engineer * **Generative Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Laila Al-Qahtani, AI Engineer * **LLMs:** Fine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ahmed Taha, AI Engineer * **Research Focus:** ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fatima Al-Shamsi, AI Engineer * **Research Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Omar Al-Ghamdi, Data Analyst * **Programming L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Faisal Al-Dossari, Data Scientist * **Big Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Yousef Al-Mutairi, Data Analyst * **Data Gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryam Al-Abdullah, Data Analyst * **Data Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hessa Al-Mansoori, Data Analyst * **Programmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mariam Al-Hashemi, Data Scientist * **Big Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Omar Sharif, Data Analyst * **Data Governance:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zainab Al-Lawati, Data Analyst * **Data Stack:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aisha Al-Farsi, Data Analyst * **Data Processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Khalid Al-Ameri, Data Analyst * **Big Data:** ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jassim Al-Mulla, Data Scientist * **Data Archi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sara Al-Abdullah, Data Scientist * **Hadoop Ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Youssef El-Masry, Data Analyst * **Data Govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hind Al-Kuwari, Data Analyst * **Data Governan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mohammed Al-Balushi, Data Analyst * **Modern D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dana Al-Ansari, Data Analyst * **Data Modeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sarah Al-Malki, Data Scientist * **Programming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Khaled Al-Yousef, Data Analyst * **Visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Rashid Al-Naimi, Data Scientist * **Programmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Noora Al-Thani, Data Analyst * **BI Tools:** T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Reem Al-Marzooqi, Data Scientist * **Machine L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Fatima bint Faisal, Data Analyst * **BI Platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Abdullah Al-Saleh, Data Analyst * **Visualizat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            full_text\n",
       "0   Ahmed Al-Otaibi, AI Engineer * **Programming L...\n",
       "1   Layla Al-Harbi, AI Engineer * **Automation & P...\n",
       "2   Fatima Al-Zahrani, AI Engineer * **Programming...\n",
       "3   Ali Bin Nasser, AI Engineer * **Research Areas...\n",
       "4   Nasser Al-Khaldi, AI Engineer * **Programming ...\n",
       "5   Sultan Al-Fahim, AI Engineer * **CI/CD & Autom...\n",
       "6   Dana Al-Jaber, AI Engineer * **Generative Mode...\n",
       "7   Abdullah Al-Ghamdi, AI Engineer * **Research A...\n",
       "8   Yasmin Al-Jassim, AI Engineer * **Programming ...\n",
       "9   Ibrahim Al-Saeed, AI Engineer * **Programming:...\n",
       "10  Hamad Al-Ghanim, Data Scientist * **Python:** ...\n",
       "11  Faisal Al-Qahtani, AI Engineer * **Infrastruct...\n",
       "12  Nouf Al-Hamad, AI Engineer * **Model Deploymen...\n",
       "13  Omar Bin Talal, AI Engineer * **Generative Mod...\n",
       "14  Laila Al-Qahtani, AI Engineer * **LLMs:** Fine...\n",
       "15  Ahmed Taha, AI Engineer * **Research Focus:** ...\n",
       "16  Fatima Al-Shamsi, AI Engineer * **Research Int...\n",
       "17  Omar Al-Ghamdi, Data Analyst * **Programming L...\n",
       "18  Faisal Al-Dossari, Data Scientist * **Big Data...\n",
       "19  Yousef Al-Mutairi, Data Analyst * **Data Gover...\n",
       "20  Maryam Al-Abdullah, Data Analyst * **Data Mode...\n",
       "21  Hessa Al-Mansoori, Data Analyst * **Programmin...\n",
       "22  Mariam Al-Hashemi, Data Scientist * **Big Data...\n",
       "23  Omar Sharif, Data Analyst * **Data Governance:...\n",
       "24  Zainab Al-Lawati, Data Analyst * **Data Stack:...\n",
       "25  Aisha Al-Farsi, Data Analyst * **Data Processi...\n",
       "26  Khalid Al-Ameri, Data Analyst * **Big Data:** ...\n",
       "27  Jassim Al-Mulla, Data Scientist * **Data Archi...\n",
       "28  Sara Al-Abdullah, Data Scientist * **Hadoop Ec...\n",
       "29  Youssef El-Masry, Data Analyst * **Data Govern...\n",
       "30  Hind Al-Kuwari, Data Analyst * **Data Governan...\n",
       "31  Mohammed Al-Balushi, Data Analyst * **Modern D...\n",
       "32  Dana Al-Ansari, Data Analyst * **Data Modeling...\n",
       "33  Sarah Al-Malki, Data Scientist * **Programming...\n",
       "34  Khaled Al-Yousef, Data Analyst * **Visualizati...\n",
       "35  Rashid Al-Naimi, Data Scientist * **Programmin...\n",
       "36  Noora Al-Thani, Data Analyst * **BI Tools:** T...\n",
       "37  Reem Al-Marzooqi, Data Scientist * **Machine L...\n",
       "38  Fatima bint Faisal, Data Analyst * **BI Platfo...\n",
       "39  Abdullah Al-Saleh, Data Analyst * **Visualizat..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_cvs[['full_text']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde3ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF_IDF vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,      # Convert to lowercase\n",
    "    stop_words='english', # Remove English stop words\n",
    "    max_features=5000,   # Limit vocabulary to top 5000 terms\n",
    "    ngram_range=(1, 2)   # Use both unigrams and bigrams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6203866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 9765 stored elements and shape (40, 5000)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors = vectorizer.fit_transform(df['full_text'])\n",
    "document_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "116745b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vectors shape: (40, 5000)\n",
      "  - 40 documents\n",
      "  - 5000 features (terms in vocabulary)\n",
      "\n",
      "This is a sparse matrix. Let's check sparsity:\n",
      "  - Non-zero elements: 9,765\n",
      "  - Total elements: 200,000\n",
      "  - Sparsity: 95.12%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document vectors shape: {document_vectors.shape}\")\n",
    "print(f\"  - {document_vectors.shape[0]} documents\")\n",
    "print(f\"  - {document_vectors.shape[1]} features (terms in vocabulary)\")\n",
    "print(\"\\nThis is a sparse matrix. Let's check sparsity:\")\n",
    "print(f\"  - Non-zero elements: {document_vectors.nnz:,}\")\n",
    "print(f\"  - Total elements: {document_vectors.shape[0] * document_vectors.shape[1]:,}\")\n",
    "print(f\"  - Sparsity: {(1 - document_vectors.nnz / (document_vectors.shape[0] * document_vectors.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query_text, top_k=10):\n",
    "    # vectorize the query text\n",
    "    query_vector = vectorizer.transform([query_text])\n",
    "    \n",
    "    # calculate the cosine_similarity \n",
    "    similarities = cosine_similarity(query_vector, document_vectors)[0]\n",
    "    \n",
    "    \n",
    "    df_results = df.copy()\n",
    "    df_results['similarity'] = similarities\n",
    "    \n",
    "   \n",
    "    return df_results.sort_values(by='similarity', ascending=False).head(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf2d36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d05f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nasser Al-Khaldi, AI Engineer * **Programming Languages:** Python, Java, Scala. * **Machine &amp; Deep Learning:** TensorFlow, Keras, PyTorch, Scikit-learn, OpenCV. * **Deployment &amp; Cloud Computing:** Docker, Kubernetes, Azure ML, AWS SageMaker. * **Specializations:** Computer Vision, Predictive Analytics.  --- Automated Quality Control System | Computer Vision Engineer [03/2023 - 06/2023]  Developed a CNN-based model to detect manufacturing defects with 99.5% accuracy.  Deployed the model on an edge device using TensorFlow Lite for real-time inference. Customer Churn Prediction Model | Machine Learning Engineer [08/2022 - 11/2022]  Built a model to predict customer churn, which helped reduce churn by 15%.  Utilized SHAP for model interpretability, providing insights into churn drivers.  --- AI Engineer Saudi Aramco | Dhahran [07/2022] – [Present]  Developing and deploying machine learning models for predictive maintenance on oil and gas equipment.  Reduced equipment downtime by 20% by predicting failures before they occur.  Working on a team to build a centralized MLOps platform. Junior AI Engineer SABIC | Riyadh [06/2020] – [06/2022]  Assisted in the development of models for optimizing chemical manufacturing processes.  Contributed to a 5% increase in production efficiency.  --- Master of Science in Artificial Intelligence King Abdullah University of Science and Technology (KAUST) | Thuwal [05/2020] Bachelor of Science in Computer Engineering King Fahd University of Petroleum and Minerals (KFUPM) | Dhahran [05/2018]</td>\n",
       "      <td>0.166469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              full_text  \\\n",
       "4  Nasser Al-Khaldi, AI Engineer * **Programming Languages:** Python, Java, Scala. * **Machine & Deep Learning:** TensorFlow, Keras, PyTorch, Scikit-learn, OpenCV. * **Deployment & Cloud Computing:** Docker, Kubernetes, Azure ML, AWS SageMaker. * **Specializations:** Computer Vision, Predictive Analytics.  --- Automated Quality Control System | Computer Vision Engineer [03/2023 - 06/2023]  Developed a CNN-based model to detect manufacturing defects with 99.5% accuracy.  Deployed the model on an edge device using TensorFlow Lite for real-time inference. Customer Churn Prediction Model | Machine Learning Engineer [08/2022 - 11/2022]  Built a model to predict customer churn, which helped reduce churn by 15%.  Utilized SHAP for model interpretability, providing insights into churn drivers.  --- AI Engineer Saudi Aramco | Dhahran [07/2022] – [Present]  Developing and deploying machine learning models for predictive maintenance on oil and gas equipment.  Reduced equipment downtime by 20% by predicting failures before they occur.  Working on a team to build a centralized MLOps platform. Junior AI Engineer SABIC | Riyadh [06/2020] – [06/2022]  Assisted in the development of models for optimizing chemical manufacturing processes.  Contributed to a 5% increase in production efficiency.  --- Master of Science in Artificial Intelligence King Abdullah University of Science and Technology (KAUST) | Thuwal [05/2020] Bachelor of Science in Computer Engineering King Fahd University of Petroleum and Minerals (KFUPM) | Dhahran [05/2018]   \n",
       "\n",
       "   similarity  \n",
       "4    0.166469  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = retrieve_documents(query_text='AI Engineer', top_k=1)\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036631f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134f187",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- **TF-IDF** is a simple but effective method for information retrieval\n",
    "- **Sparse matrices** make TF-IDF scalable to large document collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428874e6",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "- Explore other scikit-learn datasets (e.g., `fetch_20newsgroups` with different subsets)\n",
    "- Try advanced techniques like BM25 (can be implemented with sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_csv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
